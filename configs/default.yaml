# Default Configuration for Fred-LLM
# This is the standard configuration for development and testing

# Dataset settings
dataset:
  path: data/processed/equations.json
  format: json
  max_samples: null  # Use all samples
  split_ratio:
    train: 0.8
    val: 0.1
    test: 0.1

# Model settings
model:
  provider: openai
  name: gpt-4o-mini
  temperature: 0.1
  max_tokens: 2048
  timeout: 60

# Prompting settings
prompting:
  style: chain-of-thought  # basic, chain-of-thought, few-shot, tool-assisted
  include_examples: true
  num_examples: 3
  output_format: symbolic  # symbolic, series, code

# Evaluation settings
evaluation:
  mode: both  # symbolic, numeric, both
  symbolic_tolerance: 1e-10
  numeric_tolerance: 1e-6
  num_test_points: 100
  integration_domain:
    a: 0
    b: 1

# Output settings
output:
  dir: outputs
  save_predictions: true
  save_metrics: true
  log_level: INFO
