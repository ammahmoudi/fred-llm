# Complete Configuration Template
# This file shows ALL available options with documentation
# Use this as reference when creating your own configs

dataset:
  # Option 1: Raw dataset (for data preparation)
  raw:
    path: data/raw/Fredholm_Dataset_Sample.csv
    output_dir: null  # Optional: defaults to data/processed/run_<timestamp>
    max_samples: null  # Optional: limit samples (null = all)
    
    # Stratified sampling: Create balanced test sets with N samples per solution type
    # Order: Load → Augment → Sample → Split
    # - Augmentation adds edge cases to original data
    # - Sampling selects N equations per solution type (from augmented data)
    # - Splitting divides sampled data into train/val/test
    # 
    # Example: 5000 original → augment 1.15x → 5750 total
    #          → sample 1 per type → 7 equations (includes edge cases!)
    #          → split → distribute those 7
    # 
    # Recommended strategies:
    # A) Diverse test-only: samples_per_type=1, split=false → All types in one file
    # B) Balanced train+test: samples_per_type=5+, split=true → All types per split
    # C) With augmentation: augment=true + samples_per_type=1 → Diverse with edge cases
    # 
    # Solution types: exact_symbolic, series, discrete_points, 
    #   approx_coef, family, regularized, none
    stratified_sample: false  # true = enable balanced sampling
    samples_per_type: 1  # Number to sample from each solution type
    
    # Note: Sampling happens AFTER augmentation, so you get diverse edge cases too!
    #       7 types × 1 sample = 7 equations (may include augmented edge cases)
    
    # Augmentation
    augment: false
    augment_multiplier: 1.15
    augment_strategies: null  # null = default (substitute, scale, shift)
    # Available: [approx_coef, discrete_points, series, family, regularized, none_solution]
    include_edge_metadata: false
    
    # Validation
    validate_data: true
    
    # Splitting
    split: true
    split_ratios: [0.7, 0.15, 0.15]
    
    # Format conversion
    convert_formats: [infix]  # Available: [infix, latex, rpn, tokenized, python]
    output_format: both  # both | json | csv
  
  # Option 2: Prepared dataset (pre-split data)
  prepared:
    train_path: null
    val_path: null
    test_path: null
    format: null  # null = auto-detect, or specify: infix|latex|rpn|tokenized|python
    max_samples: null
    
    # Stratified sampling: Sample from already-prepared data
    # Useful for quickly testing on a balanced subset without re-preparing
    # Applied after loading files, creates new sampled files in output directory
    stratified_sample: false  # true = sample N from each solution type
    samples_per_type: 1  # Number per type (1=diverse, 5=small balanced, 10+=large)
  
  # Prompt generation (on-the-fly)
  prompting:
    style: basic  # basic|chain-of-thought|few-shot|tool-assisted
    output_dir: null  # Optional: defaults to data/prompts/<style>
    input_dir: null  # Optional: auto-chained from preparation output
    edge_case_mode: none  # none|guardrails|hints
    num_examples: 3
    include_ground_truth: true
    format: null  # null = auto-detect from input
  
  # Option 3: Pre-generated prompts
  prompts:
    prompts_dir: null
    style: null

# Model configuration (optional - omit to skip inference)
model:
  provider: openai  # openai|openrouter|local
  name: gpt-4o-mini
  
  # API Key (optional - provider determines env var to use):
  # - OpenAI provider → uses OPENAI_API_KEY from .env
  # - OpenRouter provider → uses OPENROUTER_API_KEY from .env
  # - Uncomment to override with direct key (NOT recommended for version control)
  # api_key: sk-your-key-here
  
  base_url: null
  temperature: 0.1
  max_tokens: 2048
  timeout: 60

# Evaluation configuration (optional)
evaluation:
  mode: both  # symbolic|numeric|both
  symbolic_tolerance: 1e-10
  numeric_tolerance: 1e-6
  num_test_points: 100

# Output configuration
output:
  dir: outputs
  save_predictions: true
  save_metrics: true
  log_level: INFO  # DEBUG|INFO|WARNING|ERROR
