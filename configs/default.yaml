# Default Configuration for Fred-LLM
# This is the standard configuration for development and testing

dataset:
  # Pre-split dataset (prepared data)
  prepared:
    train_path: data/processed/training_data/train_infix.csv
    val_path: data/processed/training_data/val_infix.csv
    test_path: data/processed/training_data/test_infix.csv
    format: null  # Auto-detected. Can specify: infix, latex, rpn
    max_samples: null  # Use all samples
  
  # Prompt generation on-the-fly
  prompting:
    style: chain-of-thought  # basic, chain-of-thought, few-shot, tool-assisted
    edge_case_mode: none  # none, guardrails, hints
    num_examples: 2
    include_ground_truth: true

# Model settings
model:
  provider: openai
  name: gpt-4o-mini
  temperature: 0.1
  max_tokens: 2048
  timeout: 60

# Evaluation settings
evaluation:
  mode: both
  symbolic_tolerance: 1e-10
  numeric_tolerance: 1e-6
  num_test_points: 100
  type_tolerances:
    series: 1e-2
    approx_coef: 1e-3
    regularized: 1e-3

# Output settings
output:
  dir: outputs
  save_predictions: true
  save_metrics: true
  log_level: INFO
