# Fred-LLM Configuration
# Runtime settings for Fredholm integral equation solver

# Dataset settings
dataset:
  name: "FIE-500k"
  path: "data/raw/fie_500k.json"
  processed_path: "data/processed/"
  format: "json"  # json, csv, parquet
  max_samples: null  # null for all samples

# Model settings
model:
  provider: "openai"  # openai, local, huggingface
  name: "gpt-4"
  api_key_env: "OPENAI_API_KEY"
  base_url: null  # for local models or custom endpoints
  temperature: 0.1
  max_tokens: 2048
  timeout: 60

# Prompt settings
prompting:
  style: "chain-of-thought"  # basic, chain-of-thought, few-shot, tool-assisted
  template_dir: "data/prompts/"
  include_examples: true
  num_examples: 3

# Evaluation settings
evaluation:
  mode: "both"  # symbolic, numeric, both
  symbolic_tolerance: 1e-10
  numeric_tolerance: 1e-6
  test_points: 100
  integration_method: "quad"  # quad, trapz, simpson

# Output settings
output:
  format: "latex"  # latex, rpn, python, sympy
  save_intermediate: true
  results_dir: "data/processed/results/"

# Logging settings
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_to_file: true
  log_dir: "logs/"

# Integral equation parameters
equation:
  kernel_types:
    - "polynomial"
    - "exponential"
    - "trigonometric"
    - "separable"
  domain:
    a: 0.0
    b: 1.0
  lambda_range:
    min: 0.1
    max: 2.0
